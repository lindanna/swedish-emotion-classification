{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a76bd7-a487-424f-85e7-e819de01651e",
   "metadata": {},
   "source": [
    "## Demo of BERT fine-tuned on Brighter dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1487a",
   "metadata": {},
   "source": [
    "This notebook demonstrates inference using a BERT model fine-tuned on the Swedish subset of the [BRIGHTER dataset](https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories). \n",
    "\n",
    "**Base model:** [KB-BERT](https://huggingface.co/KBLab/bert-base-swedish-cased)\n",
    "\n",
    "### Dataset Information\n",
    "\n",
    "**Dataset size:** 3,963 examples\n",
    "\n",
    "**Label distribution:**\n",
    "- Joy: 1,584 (40.6%)\n",
    "- Anger: 813 (20.8%)\n",
    "- Disgust: 748 (19.2%)\n",
    "- Sadness: 470 (12.0%)\n",
    "- Surprise: 189 (4.8%)\n",
    "- Fear: 100 (2.6%)\n",
    "\n",
    "The original dataset splits were reorganized to use 80% for training, 10% for validation, and 10% for testing.\n",
    "\n",
    "### Handling Class Imbalance\n",
    "\n",
    "To account for the imbalanced distribution, two techniques were used:\n",
    "1. **Upsampling** of rare labels (fear ×4, surprise ×2)\n",
    "2. **Weighted loss** (BCEWithLogitsLoss with pos_weight)\n",
    "\n",
    "### Performance\n",
    "\n",
    "**Overall metrics:**\n",
    "- F1 micro: 0.77\n",
    "- F1 macro: 0.67\n",
    "- Accuracy: 0.68\n",
    "\n",
    "**Per-label F1 scores:**\n",
    "- Joy: 0.95\n",
    "- Anger: 0.73\n",
    "- Disgust: 0.72\n",
    "- Sadness: 0.72\n",
    "- Fear: 0.57\n",
    "- Surprise: 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf9569-ce86-480f-a98c-91a00802fdf9",
   "metadata": {},
   "source": [
    "This code demonstrates a BERT-model fine-tuned on the Swedish subset [Brighter dataset](https://huggingface.co/datasets/brighter-dataset/BRIGHTER-emotion-categories). The base model is [KB-BERT](https://huggingface.co/KBLab/bert-base-swedish-cased).\n",
    "\n",
    "The original dataset splits were not kept as the training split was smaller than the others, instead the majority was used for training. The distribution of labels in the full dataset are not balanced:\n",
    "\n",
    "Dataset size: 3963 examples <br>\n",
    "Label distribution:\n",
    "- anger     :   813 ( 20.8%)\n",
    "- disgust   :   748 ( 19.2%)\n",
    "- fear      :   100 (  2.6%)\n",
    "- joy       :  1584 ( 40.6%)\n",
    "- sadness   :   470 ( 12.0%)\n",
    "- surprise  :   189 (  4.8%)\n",
    "\n",
    "In order to account for the class-imbalance, upsampling of the low frequency classes and weighted loss was employed.\n",
    "Results after fine-tuning:\n",
    "\n",
    "Per-label F1 score (test):\n",
    " - anger     : 0.7253\n",
    " - disgust   : 0.7168\n",
    " - fear      : 0.5714\n",
    " - joy       : 0.9467\n",
    " - sadness   : 0.7200\n",
    " - surprise  : 0.3492\n",
    "\n",
    "Test Results:\n",
    "- eval_f1_micro: 0.7724\n",
    "- eval_f1_macro: 0.6716\n",
    "- eval_accuracy: 0.6801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1647c704-8478-4eba-9abf-91114b084ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/Documents/frånphd/fromserver/arbetsprov/env/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c8727",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25abb4b9-fc49-4b83-8fe8-1b6d84c7433e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 201/201 [00:00<00:00, 1503.93it/s, Materializing param=classifier.weight]                                      \n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = 'sbx/KB-bert-base-swedish-cased_emotions_brighter'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30198810-7baf-4ca5-bc94-c5667b15886b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_single_sent(sent,tokenizer,model):\n",
    "\n",
    "    label_list = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
    "\n",
    "    #threshold to filter out labels with lower scores\n",
    "    threshold=0.1\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        sent,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length= 512,\n",
    "        padding='max_length',\n",
    "        truncation = True\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits  \n",
    "        probs = torch.sigmoid(logits).squeeze().tolist()  \n",
    "        \n",
    "    label_scores = list(zip(label_list, probs))\n",
    "\n",
    "    predicted_labels = sorted(\n",
    "        [(label,round(score,2)) for label,score in label_scores if score > threshold],\n",
    "        key=lambda x:x[1],\n",
    "        reverse=True)\n",
    "\n",
    "    labels_str = (\n",
    "        \"|\"\n",
    "        if not predicted_labels\n",
    "        else \"|\" + \"|\".join(f\"{lbl},{score:.2f}\" for lbl, score in predicted_labels) + \"|\")\n",
    "\n",
    "    return sent,labels_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ef3b830-a985-45c9-915e-b4ef09a96852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Den här produkten lever inte alls upp till mina förväntningar, skäms!', '|anger,0.97|disgust,0.97|surprise,0.35|sadness,0.27|fear,0.16|')\n"
     ]
    }
   ],
   "source": [
    "# Try the model on a sentence\n",
    "sent_to_classify = 'Den här produkten lever inte alls upp till mina förväntningar, skäms!'\n",
    "print(get_preds_single_sent(sent_to_classify,tokenizer,model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
